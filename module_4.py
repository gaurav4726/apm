import pandas as pd
from logger import logging
import os,config
import warnings
warnings.filterwarnings("ignore")
from helper import get_response,data_quality_insights,ml_model_insights,ml_model_insights_90,insights_module_3
from dataclasses import dataclass
import pyarrow as pa
import pyarrow.parquet as pq

requirement_dict=config.requirement_dict

@dataclass
class Module4_TransformationConfig:
    module4_overall_path: str=os.path.join('artifacts',"Overall.txt")


class Module4_DataTransformation:

    def __init__(self):
        self.data_transformation_config=Module4_TransformationConfig()  
    
    def initiate_classification_model_data_transformation(self):
        logging.info("Module4 has started")

        # Import All Data Generated by previous module
        population_table = pd.read_csv('artifacts/population_table.csv')
        segment_table = pd.read_csv('artifacts/segemnt_table.csv')
        treatment_table = pd.read_csv('artifacts/treatment_table.csv')
        treatment_table[['treatment_id','treatment_label_taken']].drop_duplicates().dropna().\
        reset_index(drop=True).to_csv("treatmnent_id_mapping_with_names.csv",index=False)

        # Module 1 output
        eligibility_table_module1 = pd.read_csv('artifacts/eligibility_table_module1.csv')
        treatment_table_module1 = pd.read_csv('artifacts/treatment_table_module1.csv')
        population_table_module1 = pd.read_csv('artifacts/population_table_module1.csv')
        outcome_table_module1 = pd.read_csv('artifacts/outcome_table_module1.csv')
        segment_table_module1 = pd.read_csv('artifacts/segement_table_module1.csv')



        # Module 2 output
        classification_model_ouput = pd.read_csv('artifacts/classification_model_ouput.csv')
        F1_score = pd.read_csv('artifacts/F1_score.csv')

        list=requirement_dict['Performace_days']['Performace_Post_day']
        for i in list :
            if i==30:
                regression_output_data_30days = pd.read_parquet('artifacts/regression_output_data_30days.parquet')
                R2_score_30days = pd.read_csv('artifacts/R2_score_30days.csv')
            if i==60:
                regression_output_data_60days = pd.read_parquet('artifacts/regression_output_data_60days.parquet')
                R2_score_60days = pd.read_csv('artifacts/R2_score_60days.csv')
            if i==90:    
                regression_output_data_90days = pd.read_parquet('artifacts/regression_output_data_90days.parquet')
                R2_score_90days = pd.read_csv('artifacts/R2_score_90days.csv')

        # Module 3 output
        #### Added  Project Name in Module 3 output 
        m3_overall_output = pd.read_parquet('artifacts/m3_overall_output.parquet')
        m3_overall_output['project_name']=requirement_dict['input_dict']['project_name'][0]
        m3_overall_output['Average_treatment_effect'] = m3_overall_output['Average_treatment_effect'].apply(lambda x: max(x, 0))
        m3_overall_output.loc[m3_overall_output['Average_treatment_effect'] == 0, 'Standard_Error'] = 0
        m3_overall_output.loc[m3_overall_output['Average_treatment_effect'] == 0, 'CI'] = '[0,0]'
        
        treatmnent_id_mapping_with_names = pd.read_csv('artifacts/treatmnent_id_mapping_with_names.csv')
        treatment_id_mapping = pd.read_csv('artifacts/treatment_id_mapping.csv')
        treatment_id_mapping.drop(columns=['Unnamed: 0'])
        treatment_mapping=treatmnent_id_mapping_with_names.merge(treatment_id_mapping,on=['treatment_id'])
        treatment_mapping = dict(zip(treatment_mapping['mapped_value'], treatment_mapping['treatment_label_taken']))
        
        m3_overall_output['treatment_id'] = m3_overall_output['treatment_id'].map(treatment_mapping)
        m3_overall_output = m3_overall_output.drop(columns=['Segment_Name','Segment'])
        m3_overall_output = m3_overall_output[['treatment_id','KPI','Average_treatment_effect', 'Standard_Error', 'CI', 'Significance', 'project_name']].sort_values(['treatment_id','KPI']).reset_index(drop=True)
        m3_overall_output['Average_treatment_effect'] = round(m3_overall_output['Average_treatment_effect'],2)
        m3_overall_output['Standard_Error'] = round(m3_overall_output['Standard_Error'],2)
        m3_overall_output = m3_overall_output.rename(columns={'treatment_id':'treatment_label'})

        m3_overall_output.to_csv("artifacts/m3_overall_output_.csv",index=False)
        m3_overall_output=pa.Table.from_pandas(m3_overall_output)
        pq.write_table(m3_overall_output,'artifacts/m3_overall_output_.parquet')  
        



        m3_segmentwise_output = pd.read_parquet('artifacts/m3_segmentwise_output.parquet')
        m3_segmentwise_output['project_name']=requirement_dict['input_dict']['project_name'][0]
        m3_segmentwise_output['Average_treatment_effect'] = m3_segmentwise_output['Average_treatment_effect'].apply(lambda x: max(x, 0))
        m3_segmentwise_output.loc[m3_segmentwise_output['Average_treatment_effect'] == 0, 'Standard_Error'] = 0
        m3_segmentwise_output.loc[m3_segmentwise_output['Average_treatment_effect'] == 0, 'CI'] = '[0,0]'
        
        m3_segmentwise_output['treatment_id'] = m3_segmentwise_output['treatment_id'].map(treatment_mapping)
        
        segment_labels=pd.read_csv("artifacts/segment_labels.csv")
        segment_labels['Segment']=segment_labels['Segment'].astype(str)
        m3_segmentwise_output=m3_segmentwise_output.merge(segment_labels,on=['Segment','Segment_Name'],how='left')
        m3_segmentwise_output['Segments']=m3_segmentwise_output['Segments'].fillna("Overall")
        del m3_segmentwise_output['Segment']
        
        #m3_segmentwise_output = m3_segmentwise_output.drop(columns=['Unnamed: 0'])
        m3_segmentwise_output = m3_segmentwise_output[['treatment_id','KPI','Segment_Name','Segments','Average_treatment_effect', 'Standard_Error', 'CI', 'Significance', 'project_name']].sort_values(['treatment_id','KPI']).reset_index(drop=True)
        m3_segmentwise_output['Average_treatment_effect'] = round(m3_segmentwise_output['Average_treatment_effect'],2)
        m3_segmentwise_output['Standard_Error'] = round(m3_segmentwise_output['Standard_Error'],2)
        m3_segmentwise_output = m3_segmentwise_output.rename(columns={'treatment_id':'treatment_label','Segment_Name':'Segment','Segments':'Segment_Name'})
        m3_segmentwise_output = m3_segmentwise_output[m3_segmentwise_output['Segment']!='Overall']
        
        m3_segmentwise_output.to_csv("artifacts/m3_segmentwise_output_.csv",index=False)
        m3_segmentwise_output=pa.Table.from_pandas(m3_segmentwise_output)
        pq.write_table(m3_segmentwise_output,'artifacts/m3_segmentwise_output_.parquet')
        

        #   Start Module 3 importing 
        m3_overall_output = pd.read_parquet('artifacts/m3_overall_output_.parquet')
        m3_segmentwise_output = pd.read_parquet('artifacts/m3_segmentwise_output_.parquet')

        #treatment_id_mapping=pd.read_csv("artifacts/treatment_id_mapping.csv")
        #segment_labels=pd.read_csv("artifacts/segment_labels.csv")
        #m3_segmentwise_output=m3_segmentwise_output.merge(treatment_id_mapping,left_on='treatment_id',right_on='mapped_value',how='left')
        #m3_segmentwise_output.drop(columns=['treatment_id_x','mapped_value'],axis=1,inplace=True)
        #m3_segmentwise_output.rename(columns={'treatment_id_y':'treatment_id'},inplace=True)
        #segment_labels['Segment']=segment_labels['Segment'].astype(str)
        #m3_segmentwise_output=m3_segmentwise_output.merge(segment_labels,on=['Segment','Segment_Name'],how='left')
        #m3_segmentwise_output['Segments']=m3_segmentwise_output['Segments'].fillna("Overall")
        #del m3_segmentwise_output['Segment']
        #m3_segmentwise_output.to_csv("artifacts/m3_segmentwise_output_.csv",index=False)

        logging.info("Module4 Read  Successful all dataset from previous modules")

    

        if len(list)==3:
            Feature_Importance,CM_insights,CM_accuracy_and_reliability,ML_insights = ml_model_insights(
            eligibility_table_module1,treatment_table_module1,population_table_module1,outcome_table_module1,
            segment_table_module1, classification_model_ouput,F1_score,regression_output_data_30days,
            regression_output_data_60days, regression_output_data_90days,R2_score_30days,R2_score_60days,R2_score_90days)

        else:
            for i in list :
                if i==90:
                    Feature_Importance,CM_insights,CM_accuracy_and_reliability,ML_insights = ml_model_insights_90(
            eligibility_table_module1,treatment_table_module1,population_table_module1,outcome_table_module1,
            segment_table_module1, classification_model_ouput,F1_score, regression_output_data_90days,R2_score_90days)
        logging.info("Module4 , ml_model_insights function run successfully ")   

        a,b,c,d,e,f,g = data_quality_insights(population_table,segment_table,treatment_table)
        combined_list = '--DATA QUALITY INSIGHTS--' + a + b + c + d + e + f + g + '\n' + '\n' +\
               "--Classification_Model_insights--" + CM_insights + '\n' + '\n' +\
               "--Regression_Model_insights--" + ML_insights + '\n' + '\n' +\
               '--Feature importance_insights--' + Feature_Importance + '\n' + '\n' +\
               "--MATCHING INSIGHTS--" + '\n'

        
        insights_3=insights_module_3()

        dq= a + b + c + d + e + f + g
        dataframe_insights=pd.DataFrame()
        list_name=['Data_Quality_Insights','Classification_Model_insights','Regression_Model_insights','Feature_importance_insights',"Matching_insights"]
        list_insights=[dq,CM_insights,ML_insights,Feature_Importance,insights_3]
        dataframe_insights['Category']=list_name
        dataframe_insights['insights']=list_insights
        #dataframe_insights['insights'] = dataframe_insights['insights'].str.replace('\n\n', '')
        dataframe_insights.to_csv("artifacts/final_insights_in_dataframe.csv",index=False)

        final_insights = [combined_list + insights_3[0]] + insights_3[1:]
        logging.info("Module4 , module3_insights function run successfully ")
        os.makedirs(os.path.dirname(self.data_transformation_config.module4_overall_path),exist_ok=True)
        pd.DataFrame(final_insights).to_csv('artifacts/final_insights.csv',index=False)
        logging.info("All insights saved in artifacts columns")
        logging.info("Module4 has completed")
        


if __name__=="__main__":
    obj=Module4_DataTransformation()
    obj.initiate_classification_model_data_transformation()     

   
